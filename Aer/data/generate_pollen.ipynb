{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b99ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading zones from existing CSV indice_pollen_bretagne_epci.csv ...\n",
      "Using 62 zones for generation.\n",
      "Generating daily measurements (this may take a little while)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [00:01<00:00, 38.23zone/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated file written to indice_pollen_bretagne_epci_generated.csv. Rows: 135904\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "generate_pollen.py\n",
    "\n",
    "Generates fictional but plausible daily pollen measurements for each zone\n",
    "found in `indice_pollen_bretagne_epci.csv` (if present) or synthesizes 62 zones,\n",
    "for the date range 2020-01-01 .. 2025-12-31.\n",
    "\n",
    "Output: indice_pollen_bretagne_epci_generated.csv\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----------------------\n",
    "# Config\n",
    "# ----------------------\n",
    "INPUT_CSV = \"indice_pollen_bretagne_epci.csv\"\n",
    "OUTPUT_CSV = \"indice_pollen_bretagne_epci_generated.csv\"\n",
    "START_DATE = datetime(2020, 1, 1)\n",
    "END_DATE = datetime(2025, 12, 31)\n",
    "RNG_SEED = 42  # change or set to None for non-deterministic results\n",
    "N_SYNTHETIC_ZONES = 62\n",
    "TYPE_ZONE_DEFAULT = \"EPCI\"\n",
    "SOURCE_DEFAULT = \"Air Breizh\"\n",
    "EPSG_DEFAULT = \"2154\"  # per your sample\n",
    "COUL_MAP = {1: \"#50F0E6\", 2: \"#50CCAA\", 3: \"#F0C050\", 4: \"#FF5050\", 0: \"#FFFFFF\"}\n",
    "LIB_QUAL_MAP = {1: \"Bon\", 2: \"Moyen\", 3: \"Dégradé\", 4: \"Mauvais\", 0: \"No Data\"}\n",
    "\n",
    "# species order in CSV:\n",
    "SPECIES = [\"ambroisie\", \"aulne\", \"armoise\", \"bouleau\", \"graminees\", \"olivier\"]\n",
    "\n",
    "# ----------------------\n",
    "# Utilities\n",
    "# ----------------------\n",
    "if RNG_SEED is not None:\n",
    "    random.seed(RNG_SEED)\n",
    "    np.random.seed(RNG_SEED)\n",
    "\n",
    "def date_range(start, end):\n",
    "    d = start\n",
    "    while d <= end:\n",
    "        yield d\n",
    "        d += timedelta(days=1)\n",
    "\n",
    "def month_frac(dt):\n",
    "    \"\"\"Return a fractional month index 1..12 for season functions.\"\"\"\n",
    "    return dt.month + (dt.day - 1) / 31.0\n",
    "\n",
    "# seasonal \"activity\" functions for species (0..1)\n",
    "def season_activity(species, dt):\n",
    "    m = dt.month\n",
    "    # Rough seasonal peaks (based on typical pollen seasons in temperate Europe)\n",
    "    if species == \"bouleau\":  # birch: spring (Mar-Apr-May)\n",
    "        peak = 4\n",
    "        width = 2.0\n",
    "    elif species == \"graminees\":  # grasses: late spring to summer (May-Jun-Jul)\n",
    "        peak = 6\n",
    "        width = 3.0\n",
    "    elif species == \"aulne\":  # alder: late winter - early spring (Feb-Mar-Apr)\n",
    "        peak = 3\n",
    "        width = 1.8\n",
    "    elif species == \"armoise\":  # mugwort / artemisia: late summer - early autumn (Aug-Sep)\n",
    "        peak = 8.5\n",
    "        width = 1.5\n",
    "    elif species == \"ambroisie\":  # ragweed: late summer - autumn (Aug-Sep)\n",
    "        peak = 9\n",
    "        width = 1.2\n",
    "    elif species == \"olivier\":  # olive: localized, low in Brittany; small year-round baseline with tiny spring peak\n",
    "        peak = 5\n",
    "        width = 1.0\n",
    "    else:\n",
    "        peak = 6\n",
    "        width = 3.0\n",
    "\n",
    "    # Use a wrapped Gaussian around months 1..12\n",
    "    # Convert month to angle on circle\n",
    "    angle = (m - peak) * (2 * math.pi / 12)\n",
    "    val = math.exp(- (angle ** 2) / (2 * ( (width * 2*math.pi/12) ** 2)))\n",
    "    # add small baseline noise\n",
    "    baseline = 0.03 if species == \"olivier\" else 0.02\n",
    "    return baseline + (1.0 - baseline) * val\n",
    "\n",
    "def activity_to_code(activity_value, overall_quality_code):\n",
    "    \"\"\"\n",
    "    Map an activity value (0..1) and overall quality to an integer code 1..4.\n",
    "    We bias species code by activity and by the overall qualitative situation.\n",
    "    \"\"\"\n",
    "    # combined score [0..1]\n",
    "    # overweight the activity but include some noise and quality effect\n",
    "    score = 0.7 * activity_value + 0.2 * (1 - (overall_quality_code - 1) / 3.0)  # better overall quality -> lower pollen\n",
    "    score += random.uniform(-0.08, 0.08)\n",
    "    # thresholds (tuned to produce many 1-2, some 3, few 4)\n",
    "    if score < 0.25:\n",
    "        return 1\n",
    "    elif score < 0.55:\n",
    "        return 2\n",
    "    elif score < 0.80:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "\n",
    "# ----------------------\n",
    "# Load / discover zones\n",
    "# ----------------------\n",
    "if os.path.exists(INPUT_CSV):\n",
    "    print(f\"Reading zones from existing CSV {INPUT_CSV} ...\")\n",
    "    src = pd.read_csv(INPUT_CSV, dtype=str)\n",
    "    # ensure columns we need exist; try to coerce coords to numeric if present\n",
    "    for c in [\"code_zone\", \"lib_zone\", \"x_wgs84\", \"y_wgs84\", \"x_reg\", \"y_reg\", \"epsg_reg\"]:\n",
    "        if c not in src.columns:\n",
    "            print(f\"Warning: input CSV missing column {c}; synthesizing zones instead.\")\n",
    "            src = None\n",
    "            break\n",
    "else:\n",
    "    src = None\n",
    "\n",
    "zones = []\n",
    "if src is not None:\n",
    "    # get unique zones by code_zone; keep first seen coordinates\n",
    "    unique = src.drop_duplicates(subset=[\"code_zone\"])\n",
    "    # if there are more than 61 keep all\n",
    "    for _, row in unique.iterrows():\n",
    "        cz = str(row.get(\"code_zone\", \"\")).strip()\n",
    "        if cz == \"\" or pd.isna(cz):\n",
    "            continue\n",
    "        lib = row.get(\"lib_zone\", cz)\n",
    "        try:\n",
    "            x_w = float(row.get(\"x_wgs84\", np.nan))\n",
    "            y_w = float(row.get(\"y_wgs84\", np.nan))\n",
    "        except Exception:\n",
    "            x_w, y_w = np.nan, np.nan\n",
    "        try:\n",
    "            x_reg = float(row.get(\"x_reg\", np.nan))\n",
    "            y_reg = float(row.get(\"y_reg\", np.nan))\n",
    "        except Exception:\n",
    "            x_reg, y_reg = x_w, y_w\n",
    "        epsg = row.get(\"epsg_reg\", EPSG_DEFAULT)\n",
    "        zones.append({\n",
    "            \"code_zone\": cz,\n",
    "            \"lib_zone\": lib,\n",
    "            \"x_wgs84\": x_w,\n",
    "            \"y_wgs84\": y_w,\n",
    "            \"x_reg\": x_reg,\n",
    "            \"y_reg\": y_reg,\n",
    "            \"epsg_reg\": epsg\n",
    "        })\n",
    "\n",
    "if len(zones) < N_SYNTHETIC_ZONES:\n",
    "    print(\"Synthesizing zones (not enough existing zones found)...\")\n",
    "    zones = []\n",
    "    # bounding box for Brittany approx lon [-5.5, -1.0], lat [47.0, 49.5]\n",
    "    for i in range(N_SYNTHETIC_ZONES):\n",
    "        lon = random.uniform(-5.5, -1.0)\n",
    "        lat = random.uniform(47.0, 49.5)\n",
    "        code = f\"Z{1000 + i}\"\n",
    "        lib = f\"Zone synthétique {i+1}\"\n",
    "        # for x_reg/y_reg use placeholder projected coords (not real projection)\n",
    "        x_reg = 100000 + (lon + 6.0) * 50000 + random.uniform(-1000, 1000)\n",
    "        y_reg = 6000000 + (lat - 46.0) * 10000 + random.uniform(-1000, 1000)\n",
    "        zones.append({\n",
    "            \"code_zone\": code,\n",
    "            \"lib_zone\": lib,\n",
    "            \"x_wgs84\": lon,\n",
    "            \"y_wgs84\": lat,\n",
    "            \"x_reg\": x_reg,\n",
    "            \"y_reg\": y_reg,\n",
    "            \"epsg_reg\": EPSG_DEFAULT\n",
    "        })\n",
    "\n",
    "print(f\"Using {len(zones)} zones for generation.\")\n",
    "\n",
    "# ----------------------\n",
    "# For each zone, define absence periods (no sampling)\n",
    "# ----------------------\n",
    "zone_absences = {}\n",
    "for z in zones:\n",
    "    # For each zone pick 1..4 absence intervals (to simulate station downtime / seasonal no-sampling)\n",
    "    n_abs = random.choice([1,1,1,2])  # most zones have 1 absence block, some 2\n",
    "    abs_periods = []\n",
    "    total_days = (END_DATE - START_DATE).days + 1\n",
    "    for _ in range(n_abs):\n",
    "        length = random.randint(15, min(150, total_days//2))  # days\n",
    "        # pick a random start\n",
    "        start_offset = random.randint(0, max(0, total_days - length))\n",
    "        astart = START_DATE + timedelta(days=start_offset)\n",
    "        aend = astart + timedelta(days=length-1)\n",
    "        abs_periods.append((astart, aend))\n",
    "    # Merge overlapping intervals\n",
    "    abs_periods_sorted = sorted(abs_periods, key=lambda x: x[0])\n",
    "    merged = []\n",
    "    for s,e in abs_periods_sorted:\n",
    "        if not merged or s > merged[-1][1] + timedelta(days=1):\n",
    "            merged.append([s,e])\n",
    "        else:\n",
    "            merged[-1][1] = max(merged[-1][1], e)\n",
    "    zone_absences[z[\"code_zone\"]] = merged\n",
    "\n",
    "# ----------------------\n",
    "# Generate per-day data\n",
    "# ----------------------\n",
    "out_rows = []\n",
    "# We'll generate per zone to keep memory manageable\n",
    "total_days = (END_DATE - START_DATE).days + 1\n",
    "dates = [START_DATE + timedelta(days=i) for i in range(total_days)]\n",
    "\n",
    "print(\"Generating daily measurements (this may take a little while)...\")\n",
    "for z in tqdm(zones, unit=\"zone\"):\n",
    "    cz = z[\"code_zone\"]\n",
    "    libz = z[\"lib_zone\"]\n",
    "    xw = z[\"x_wgs84\"]\n",
    "    yw = z[\"y_wgs84\"]\n",
    "    xr = z[\"x_reg\"]\n",
    "    yr = z[\"y_reg\"]\n",
    "    epsg = z.get(\"epsg_reg\", EPSG_DEFAULT)\n",
    "\n",
    "    # Define a zone-specific baseline pollution tendency (1..4) biased to 1-2\n",
    "    baseline = random.choices([1,2,3,4], weights=[40,35,18,7])[0]\n",
    "\n",
    "    # Slight long-term drift per year for variety\n",
    "    drift = np.linspace(0, random.uniform(-0.2, 0.3), total_days)\n",
    "\n",
    "    # Get absence intervals for quick check\n",
    "    abs_intervals = zone_absences.get(cz, [])\n",
    "\n",
    "    for idx, dt in enumerate(dates):\n",
    "        # check absence\n",
    "        is_absent = False\n",
    "        for s,e in abs_intervals:\n",
    "            if s <= dt <= e:\n",
    "                is_absent = True\n",
    "                break\n",
    "\n",
    "        date_ech_str = dt.strftime(\"%Y/%m/%d 00:00:00\")\n",
    "        if is_absent:\n",
    "            # all codes zero, No Data\n",
    "            row = {\n",
    "                \"date_ech\": date_ech_str,\n",
    "                \"code_qual\": \"0\",\n",
    "                \"lib_qual\": \"No Data\",\n",
    "                \"coul_qual\": COUL_MAP[0],\n",
    "                \"date_dif\": date_ech_str,\n",
    "                \"type_zone\": TYPE_ZONE_DEFAULT,\n",
    "                \"code_zone\": cz,\n",
    "                \"lib_zone\": libz,\n",
    "                \"source\": SOURCE_DEFAULT,\n",
    "                # species codes\n",
    "                \"code_ambroisie\": \"0\",\n",
    "                \"code_aulne\": \"0\",\n",
    "                \"code_armoise\": \"0\",\n",
    "                \"code_bouleau\": \"0\",\n",
    "                \"code_graminees\": \"0\",\n",
    "                \"code_olivier\": \"0\",\n",
    "                \"x_wgs84\": xw,\n",
    "                \"y_wgs84\": yw,\n",
    "                \"x_reg\": xr,\n",
    "                \"y_reg\": yr,\n",
    "                \"epsg_reg\": epsg\n",
    "            }\n",
    "            out_rows.append(row)\n",
    "            continue\n",
    "\n",
    "        # Measured day: determine an overall qualitative code (1..4)\n",
    "        # seasonal factor: overall pollen load tends to be higher in spring-summer\n",
    "        month = dt.month\n",
    "        # basic seasonal multiplier ([~0.6 in winter .. ~1.6 in peak pollen season])\n",
    "        seasonal_mult = 0.6 + 1.0 * math.exp(-((month - 6) ** 2) / (2 * 4.0))\n",
    "        # zone-specific random jitter and occasional spikes\n",
    "        spike = 1.0\n",
    "        if random.random() < 0.003:  # rare big spike day\n",
    "            spike = random.uniform(1.6, 2.5)\n",
    "        jitter = random.uniform(0.85, 1.15)\n",
    "\n",
    "        # compute a score where higher -> worse (4)\n",
    "        score = ( (baseline - 1) / 3.0 ) * 0.4 + (seasonal_mult - 0.6) / 1.0 * 0.5\n",
    "        score *= spike * jitter\n",
    "        score += random.uniform(-0.12, 0.12)\n",
    "\n",
    "        # map score to code_qual\n",
    "        if score < 0.15:\n",
    "            code_qual = 1\n",
    "        elif score < 0.45:\n",
    "            code_qual = 2\n",
    "        elif score < 0.75:\n",
    "            code_qual = 3\n",
    "        else:\n",
    "            code_qual = 4\n",
    "\n",
    "        # Occasionally enforce low or high extremes for particular zones/days\n",
    "        if random.random() < 0.002:\n",
    "            code_qual = random.choice([1,4])\n",
    "\n",
    "        lib_qual = LIB_QUAL_MAP[code_qual]\n",
    "        coul = COUL_MAP.get(code_qual, \"#000000\")\n",
    "\n",
    "        # species codes using seasonal activity and overall quality\n",
    "        species_codes = {}\n",
    "        for sp in SPECIES:\n",
    "            act = season_activity(sp, dt)\n",
    "            code = activity_to_code(act, code_qual)\n",
    "            # add noise: some low-probability anomalies\n",
    "            if random.random() < 0.01:\n",
    "                code = max(1, min(4, code + random.choice([-1,1])))\n",
    "            species_codes[sp] = code\n",
    "\n",
    "        row = {\n",
    "            \"date_ech\": date_ech_str,\n",
    "            \"code_qual\": str(code_qual),\n",
    "            \"lib_qual\": lib_qual,\n",
    "            \"coul_qual\": coul,\n",
    "            \"date_dif\": date_ech_str,\n",
    "            \"type_zone\": TYPE_ZONE_DEFAULT,\n",
    "            \"code_zone\": cz,\n",
    "            \"lib_zone\": libz,\n",
    "            \"source\": SOURCE_DEFAULT,\n",
    "            \"code_ambroisie\": str(species_codes[\"ambroisie\"]),\n",
    "            \"code_aulne\": str(species_codes[\"aulne\"]),\n",
    "            \"code_armoise\": str(species_codes[\"armoise\"]),\n",
    "            \"code_bouleau\": str(species_codes[\"bouleau\"]),\n",
    "            \"code_graminees\": str(species_codes[\"graminees\"]),\n",
    "            \"code_olivier\": str(species_codes[\"olivier\"]),\n",
    "            \"x_wgs84\": xw,\n",
    "            \"y_wgs84\": yw,\n",
    "            \"x_reg\": xr,\n",
    "            \"y_reg\": yr,\n",
    "            \"epsg_reg\": epsg\n",
    "        }\n",
    "        out_rows.append(row)\n",
    "\n",
    "# ----------------------\n",
    "# Save CSV\n",
    "# ----------------------\n",
    "df_out = pd.DataFrame(out_rows, columns=[\n",
    "    \"date_ech\",\"code_qual\",\"lib_qual\",\"coul_qual\",\"date_dif\",\"type_zone\",\n",
    "    \"code_zone\",\"lib_zone\",\"source\",\n",
    "    \"code_ambroisie\",\"code_aulne\",\"code_armoise\",\"code_bouleau\",\"code_graminees\",\"code_olivier\",\n",
    "    \"x_wgs84\",\"y_wgs84\",\"x_reg\",\"y_reg\",\"epsg_reg\"\n",
    "])\n",
    "\n",
    "# Make sure numeric columns are represented the way you prefer; keep textual codes as strings\n",
    "df_out.to_csv(OUTPUT_CSV, index=False, float_format=\"%.12g\")\n",
    "print(f\"Generated file written to {OUTPUT_CSV}. Rows: {len(df_out)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
